# ImageShift  

## Описание реализованных подходов  
### Смещение изображения на 3.5 писеля  
Смещение изображения было реализовано при помощи аффинного преобразования из модуля cv2. 
В данном случае, матрица преобразования задает сдвиг на 3.5 пикселя по обеим осям (x и y).  

Так как сдвиг задан не целым числом пикселей, новые пиксели могут находиться между исходными пикселями изображения.   
Чтобы определить цвет новых пикселей, используется метод бикубической интерполяции.

### Используемые архитектуры  
В ходе работы над проектом были опробованы различные подходы для обучения модели на основе исходного датасета.  
В числе исследованных методов были модели   GAN(Convolutional GAN, или ConvGAN), а также вариационные автоэнкодеры.  
Однако, эти подходы не дали желаемого результата; вероятно, для таких сложных моделей исходный размер датасета не является достаточным. 


Были также рассмотрены две более специализированные архитектуры.  
Первая из них - это Spatial Transformer Networks (STN). Такая архитектура была выбрана, так как она является специализированной для задач преобразования входных данных.  
На данной архитетуре (CNN + Афинные преобразования) был получен удовлетворительный результат.

Второй подход, который показался перспективным и оптимальным, включает использование единичной свертки.  
Несмотря на то, что этот метод  не демонстрирует ожидаемого качества работы (на текущий момент),  
его неудача может быть связана скорее с неточностями в пайплайне и подбором гиперпараметров, а не с принципиальной непригодностью идеи.  
Основной концепцией этого подхода является использование матрицы сдвига, которую модель оптимизирует в процессе обучения, сходясь к "правильной".

### Задача оптимизации
Изначально в качестве loss-функции использовался MSE. Однако, он не учитывает дисбаланс темных и белых(а также "серых" пикселей), при том что сдвиг определяется последними.  
Для учета "текстуры" рассчитывается MSE по вычисленному градиенту. Конечный вид функции определяется взвешенной суммой описанных выше факторов.  
Loss-функция [WG Loss](src/utils/loss_functions.py)


### Оценка ошибки
Мною было рассмотрено несколько способов, включая самых простых и очевидных (l1 и l2 норма разницы между матрицами соответствующий изображений).  
Однако наиболее стабильным критерием на произвольных изображениях и диапазонах значений сдвига показал себя оптический поток.  
Данная метрика была выбрана по двум причинам:  
1.  Оптический поток способен обнаруживать смещения между изображениями, которые меньше одного пикселя. Это особенно полезно в нашем случае, так как мы исследуем небольшой сдвиг, 3.5 пикселя.
2.  В отличие от некоторых других метрик ошибки, оптический поток учитывает пространственную структуру изображения. Это означает, что он не просто смотрит на общую разницу между двумя изображениями, но также учитывает, как эта разница распределена по изображению.

### Результаты 
#### V1
Для оптимальной модели удалось достичь разницы порядка 1e-6 между сдвигом при помощи метода opencv (изображения в Data/dataset/dist) и сдвигом в результате работы нейросети.  
(заметка: типовой порядок величины для изображений из dist и scr составялет 1e-4, на "плохих" моделях выходит такой же порядок или даже выше).
Таким образом, такой подход оптимален, так как целевой эффект очень трудно заметить "на глаз".
#### V2
Была выбрана подходящая задача оптимизиции, за счет чего удалось получить статистически значимое увеличение метрики - порядка нескольких тысячных в логарифмическом масштабе.
Теперь проект можно запустить из консоли, используя следующую команду:
```bash
python3 inference/shift.py --img_path your_path_to_image


